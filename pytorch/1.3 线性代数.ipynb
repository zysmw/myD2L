{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8388854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5c910",
   "metadata": {},
   "source": [
    "# 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af27a8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(1.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 变量由只有一个元素的张量表示\n",
    "\n",
    "# 我们实例化两个标量\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x+y, x-y, x*y, x/y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc097b",
   "metadata": {},
   "source": [
    "# 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3917c831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量可以视作由标量组成的列表\n",
    "# 我们通过一维张量处理向量\n",
    "\n",
    "# 注意：默认列向量是向量的方向！！\n",
    "\n",
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a079c505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以通过下标来引用向量的任意元素\n",
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f565052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量的长度通常称谓向量的维度，可以通过Python内置的len()函数来获取\n",
    "# 需要注意的是，“维度”这个词因为上下文可能会有歧义，对于向量来说，我们约定“维度”就是向量的长度\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e468880",
   "metadata": {},
   "source": [
    "# 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c129def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape((4, 5))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb942bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5, 10, 15],\n",
       "        [ 1,  6, 11, 16],\n",
       "        [ 2,  7, 12, 17],\n",
       "        [ 3,  8, 13, 18],\n",
       "        [ 4,  9, 14, 19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵的转置\n",
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6e9c1",
   "metadata": {},
   "source": [
    "# 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39292d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量为我们提供了描述具有任意数量轴的n维数组的通用方法\n",
    "\n",
    "# 向量是一阶张量\n",
    "# 矩阵是二阶张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590b838d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape((2,3,4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a12836cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 给定具有相同形状的任意两个张量，任何按元素⼆元运算的结果都将是相同形状的张量\n",
    "\n",
    "A = torch.arange(20, dtype=torch.float32).reshape((5,4))\n",
    "\n",
    "B = A.clone() # 通过分配新内存，将A的一个副本分配给B\n",
    "\n",
    "A, A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e26e940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 两个矩阵的按元素乘法 称为 Hadamard积，数学符号就是一个圆圈带圆心\n",
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0fccb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将张量乘以或加上⼀个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。\n",
    "a = 2\n",
    "X = torch.arange(24).reshape(2,3,4)\n",
    "\n",
    "a + X, (a*X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd09244e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(276)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算一个张量中所有元素的总和\n",
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e6b984a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([40., 45., 50., 55.]),\n",
       " tensor([ 6., 22., 38., 54., 70.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们可以指定张量沿哪一个轴来通过求和降低维度\n",
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis1 = A.sum(axis=1)\n",
    "\n",
    "A, A_sum_axis0, A_sum_axis1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "820b8a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(190.), tensor(190.))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 沿着行和列对矩阵求和，等价于对矩阵所有元素求和\n",
    "# 下面两行代码的作用一样\n",
    "\n",
    "A.sum(), A.sum(axis=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bd54abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.5000), tensor(9.5000))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 跟求和类似，我们也可以求所有元素的平均值\n",
    "# 下面代码的作用一样\n",
    "\n",
    "A.mean(), A.sum()/A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "328cf3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 同样的，求平均值也可以指定按哪个轴\n",
    "# 下面代码的作用一样\n",
    "\n",
    "A.mean(axis=0), A.sum(axis=0)/A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a821d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.],\n",
       "         [22.],\n",
       "         [38.],\n",
       "         [54.],\n",
       "         [70.]]),\n",
       " torch.Size([5, 4]),\n",
       " torch.Size([5, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以使求和后的“轴数”不变\n",
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "\n",
    "sum_A, A.shape, sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5464683b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  6.,  8., 10.],\n",
       "        [12., 15., 18., 21.],\n",
       "        [24., 28., 32., 36.],\n",
       "        [40., 45., 50., 55.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算沿某个轴的累计总和，调用cumsum()函数\n",
    "# 此函数不会降维\n",
    "\n",
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82e221df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 点积\n",
    "# 注意！调用点积计算 torch.dot()函数，对于传入的张量参数的数据类型必须一致！！！否则报错！！！\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "y = torch.ones(4, dtype=torch.float32)\n",
    "\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e1c0e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.), tensor(6.))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 点积同样可以由下述代码来计算\n",
    "(x * y).sum(), torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "178d03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用方阵的乘法来表示旋转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f016a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mv()函数用来计算矩阵—向量的乘积\n",
    "\n",
    "A.shape, x.shape, torch.mv(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e53384d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.,  6.,  6.,  6.,  6.],\n",
       "         [22., 22., 22., 22., 22.],\n",
       "         [38., 38., 38., 38., 38.],\n",
       "         [54., 54., 54., 54., 54.],\n",
       "         [70., 70., 70., 70., 70.]]),\n",
       " torch.Size([5, 4]),\n",
       " torch.Size([4, 5]),\n",
       " torch.Size([5, 5]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm()函数用来计算矩阵——矩阵的乘积\n",
    "B = torch.ones(A.T.shape)\n",
    "\n",
    "torch.mm(A, B), A.shape, B.shape, torch.mm(A, B).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce5e01e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   1.,   4.,   9.],\n",
       "         [ 16.,  25.,  36.,  49.],\n",
       "         [ 64.,  81., 100., 121.],\n",
       "         [144., 169., 196., 225.],\n",
       "         [256., 289., 324., 361.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意：矩阵的乘法不要和Hadamard积搞混了！\n",
    "A_ = A.clone()\n",
    "A * A, A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824d993",
   "metadata": {},
   "source": [
    "# 范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e2ee822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在线性代数中，向量范数是将向量映射到标量的函数F\n",
    "\n",
    "# 向量的范数要满足3个性质：\n",
    "# 1. 缩放性\n",
    "# 2. 三角不等式\n",
    "# 3. 非负"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82b772ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.norm()函数用来计算范数，默认是L2范数\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "645b0516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1范数的计算\n",
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2889193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49.6991)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.norm()函数可以直接计算一个矩阵的范数\n",
    "torch.norm(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c86abdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意：高阶张量在调用内置的len()函数时，返回的是其第一个维度\n",
    "X.shape, len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb41da5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]),\n",
       " tensor([[12, 14, 16, 18],\n",
       "         [20, 22, 24, 26],\n",
       "         [28, 30, 32, 34]]),\n",
       " tensor([[12, 15, 18, 21],\n",
       "         [48, 51, 54, 57]]),\n",
       " tensor([[ 6, 22, 38],\n",
       "         [54, 70, 86]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X.sum(axis=0), X.sum(axis=1), X.sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a8af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
